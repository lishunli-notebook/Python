{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "time.sleep(np.random.rand()+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def open_hupu():\n",
    "    ##不打开浏览器\n",
    "options = Options() \n",
    "options.add_argument(\"--headless\") \n",
    "#-------------------------\n",
    "\n",
    "#打开浏览器并且打开虎扑NBA\n",
    "driver = webdriver.Chrome()   #options = options\n",
    "driver.get('https://cn.bing.com')\n",
    "driver.find_element_by_id('sb_form_q').send_keys('虎扑NBA')\n",
    "driver.find_element_by_id('sb_form_go').click()\n",
    "driver.find_element_by_xpath('//*[@id=\"b_results\"]/li[1]/h2/a').click()\n",
    "driver.switch_to.window(driver.window_handles[-1:][0]) #切换到当前页\n",
    "    #return driver\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##点击新闻并切换到下一页\n",
    "driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/ul/li[3]/a').click()\n",
    "driver.switch_to.window(driver.window_handles[-1:][0]) #切换到当前页"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hupu_NBA(pages = 5):\n",
    "    \"\"\"\n",
    "    1.用于爬取虎扑上NBA的最新消息！\n",
    "    2.在同一个驱动里面，标签的切换只能爬取5条数据，就被停止了，找不到原因。\n",
    "        所以另外开一个驱动，打开浏览器，使用完成后，quit关闭，close只能关闭当前标签页。\n",
    "    3.如果打开了新的标签页，需要将画面切换到新的标签页才能操作，所有的标签页均在：window_handles里面，\n",
    "        每一个标签对应列表里面的一个内容。\n",
    "        1)可以使用for循环来找到最后一个标签:\n",
    "            for handle in window_handles:\n",
    "                driver.switch_to_window(handle)\n",
    "        2)也可以使用:\n",
    "            driver.switch_to_window(driver.window_handles[-1:][0])\n",
    "        3)系统提示使用：\n",
    "            driver.switch_to.window(name)\n",
    "    4.使用find_elements_by_link_text可快速找到下一页\n",
    "    5.注意get_attribute的使用\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    import time as TM\n",
    "\n",
    "    time_begin = TM.time()  #初始化时间\n",
    "    col = 0  #查找的第i个内容\n",
    "    page = 1    #初始化页数\n",
    "    column_name = ['title', 'source', 'url', 'content']\n",
    "    data = pd.DataFrame(columns=column_name)\n",
    "    \n",
    "    print('-----'*8, '\\n准备爬取第1页的内容！！')\n",
    "    os.system('say \"准备爬取第1页的内容!\"')\n",
    "    \n",
    "    while page <= pages:\n",
    "        \n",
    "        key = True  #判断是否爬完了一页的内容\n",
    "        i = 1   #初始化当前页的新闻个数\n",
    "        while key:  #爬取当前页的内容\n",
    "            try:\n",
    "\n",
    "                li = driver.find_element_by_xpath('/html/body/div[3]/div[1]/div[2]/ul/li[%s]'%(i))  #打开第i个新闻内容\n",
    "                txt = re.split(r'\\n', li.text)  #获得文本\n",
    "                title, source = txt[0], txt[1]  #获取信息\n",
    "\n",
    "                ##链接\n",
    "                link = driver.find_element_by_xpath('/html/body/div[3]/div[1]/div[2]/ul/li[%s]/div[1]/h4/a'%(i)).get_attribute('href')#获得链接\n",
    "                ##链接内容\n",
    "                ##打开一个新的driver1\n",
    "                driver1 = webdriver.Chrome(options=options)\n",
    "                driver1.get(link)\n",
    "                content = driver1.find_element_by_xpath('/html/body/div[4]/div[1]/div[2]').text\n",
    "                driver1.quit()  #关闭新建的浏览器\n",
    "\n",
    "                #整理数据到data\n",
    "                data.loc[col, :] = [title, source, link, content]\n",
    "\n",
    "                ##返回上一级标签\n",
    "                #driver.switch_to_window(driver.window_handles[-1:][0])\n",
    "                \n",
    "                    \n",
    "                i += 1  #更新到下一个新闻\n",
    "                col += 1  #更新col index\n",
    "                \n",
    "                ##没20条数据休息一会并告知我\n",
    "                if (col) % 100 == 0:\n",
    "                    print('已经爬取数据%s条！'%(col))\n",
    "                    os.system('say \"叮叮\"')\n",
    "                    TM.sleep(np.random.rand()+0.2) \n",
    "                \n",
    "                TM.sleep(np.random.rand()+0.2)  #暂停一会\n",
    "\n",
    "            except:\n",
    "                key = False\n",
    "                page += 1\n",
    "                print('已经用时%.2f秒!!'%(TM.time() - time_begin))\n",
    "                print('-----'*4)\n",
    "                \n",
    "                if page <= pages:\n",
    "                    print('正在爬取第%s页的内容！！'%(page))\n",
    "                    os.system('say \"正在爬取第%s页的内容\"'%(page))\n",
    "                    ##点击下一页\n",
    "                    driver.find_element_by_link_text('下一页').click()\n",
    "                \n",
    "                \n",
    "    print('用时%.2f秒已经爬完%s页的内容共%s条！！'%(TM.time()-time_begin, page-1,col))\n",
    "    print('******'*8)\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    os.system('say \"顺立，NBA内容已经爬取完成！请查收！\"')\n",
    "    \n",
    "    return data\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- \n",
      "准备爬取第1页的内容！！\n",
      "已经用时235.32秒!!\n",
      "--------------------\n",
      "正在爬取第2页的内容！！\n",
      "已经爬取数据100条！\n",
      "已经用时484.18秒!!\n",
      "--------------------\n",
      "正在爬取第3页的内容！！\n",
      "已经用时728.05秒!!\n",
      "--------------------\n",
      "正在爬取第4页的内容！！\n",
      "已经爬取数据200条！\n",
      "已经用时973.31秒!!\n",
      "--------------------\n",
      "正在爬取第5页的内容！！\n",
      "已经爬取数据300条！\n",
      "已经用时1222.08秒!!\n",
      "--------------------\n",
      "正在爬取第6页的内容！！\n",
      "已经用时1465.05秒!!\n",
      "--------------------\n",
      "正在爬取第7页的内容！！\n",
      "已经爬取数据400条！\n",
      "已经用时1707.07秒!!\n",
      "--------------------\n",
      "正在爬取第8页的内容！！\n",
      "已经用时1948.28秒!!\n",
      "--------------------\n",
      "正在爬取第9页的内容！！\n",
      "已经爬取数据500条！\n",
      "已经用时2205.38秒!!\n",
      "--------------------\n",
      "正在爬取第10页的内容！！\n",
      "已经爬取数据600条！\n",
      "已经用时2451.89秒!!\n",
      "--------------------\n",
      "正在爬取第11页的内容！！\n",
      "已经用时2710.78秒!!\n",
      "--------------------\n",
      "正在爬取第12页的内容！！\n",
      "已经爬取数据700条！\n",
      "已经用时2959.09秒!!\n",
      "--------------------\n",
      "正在爬取第13页的内容！！\n",
      "已经用时3211.97秒!!\n",
      "--------------------\n",
      "正在爬取第14页的内容！！\n",
      "已经爬取数据800条！\n",
      "已经用时3458.54秒!!\n",
      "--------------------\n",
      "正在爬取第15页的内容！！\n",
      "已经爬取数据900条！\n",
      "已经用时3710.08秒!!\n",
      "--------------------\n",
      "正在爬取第16页的内容！！\n",
      "已经用时3969.24秒!!\n",
      "--------------------\n",
      "正在爬取第17页的内容！！\n",
      "已经爬取数据1000条！\n",
      "已经用时4216.21秒!!\n",
      "--------------------\n",
      "正在爬取第18页的内容！！\n",
      "已经用时4470.27秒!!\n",
      "--------------------\n",
      "正在爬取第19页的内容！！\n",
      "已经爬取数据1100条！\n",
      "已经用时4718.43秒!!\n",
      "--------------------\n",
      "正在爬取第20页的内容！！\n",
      "已经爬取数据1200条！\n",
      "已经用时4975.76秒!!\n",
      "--------------------\n",
      "用时4975.76秒已经爬完20页的内容共1200条！！\n",
      "************************************************\n"
     ]
    }
   ],
   "source": [
    "df = hupu_NBA(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('虎扑NBA新闻5_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('虎扑NBA新闻5_10(GBK).csv', encoding='GBK', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这个重要！！定位到新打开的网页"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "+ for handle in driver.window_handles:#始终获得当前最后的窗口，所以多要多次使用a\n",
    "    + driver.switch_to_window(handle)\n",
    "\n",
    "+ driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[2]/ul/li[3]/a\").click() #定位到新闻并点击\n",
    "\n",
    "+ for handle in driver.window_handles:#始终获得当前最后的窗口，所以多要多次使用a\n",
    "    + driver.switch_to_window(handle)\n",
    "    \n",
    "+ ##可以使用driver.window_handles[-1:][0]找到最后一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- \n",
      "准备爬取第1页的内容！！\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "import time as TM\n",
    "\n",
    "\n",
    "\n",
    "col = 0  #查找的第i个内容\n",
    "key = True  #判断是否爬完了一页的内容\n",
    "page = 1    #初始化页数\n",
    "column_name = ['title', 'source', 'url', 'content']\n",
    "data = pd.DataFrame(columns=column_name)\n",
    "print('-----'*8, '\\n准备爬取第1页的内容！！')\n",
    "i = 1   #初始化当前页的新闻个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据1条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据2条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据3条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据4条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据5条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据6条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据7条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据8条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据9条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据10条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据11条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据12条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据13条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据14条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据15条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据16条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据17条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据18条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据19条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据20条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据21条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据22条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据23条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据24条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据25条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据26条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据27条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据28条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据29条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据30条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据31条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据32条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据33条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据34条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据35条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据36条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据37条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据38条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据39条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据40条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据41条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据42条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据43条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据44条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据45条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据46条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据47条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据48条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据49条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据50条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据51条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据52条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据53条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据54条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据55条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据56条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据57条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据58条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据59条！\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "已经爬取数据60条！\n",
      "1\n",
      "用时226.48148703575134\n"
     ]
    }
   ],
   "source": [
    "time_begin = TM.time()  #初始化时间\n",
    "while key:\n",
    "    try:\n",
    "\n",
    "        li = driver.find_element_by_xpath('/html/body/div[3]/div[1]/div[2]/ul/li[%s]'%(i))  #打开第i个新闻内容\n",
    "        txt = re.split(r'\\n', li.text)  #获得文本\n",
    "        title, source = txt[0], txt[1]  #获取信息\n",
    "       \n",
    "        ##链接\n",
    "        link = driver.find_element_by_xpath('/html/body/div[3]/div[1]/div[2]/ul/li[%s]/div[1]/h4/a'%(i)).get_attribute('href')#获得链接\n",
    "        ##链接内容\n",
    "        ##新打开一个driver1\n",
    "        driver1 = webdriver.Chrome(options=options)\n",
    "        driver1.get(link)\n",
    "        content = driver1.find_element_by_xpath('/html/body/div[4]/div[1]/div[2]').text\n",
    "        driver1.quit()  #关闭新建的浏览器\n",
    "\n",
    "        #整理数据到data\n",
    "        data.loc[col, :] = [title, source, link,content]\n",
    "\n",
    "        ##返回上一级标签\n",
    "        #driver.switch_to_window(driver.window_handles[-1:][0])\n",
    "        \n",
    "        print('已经爬取数据%s条！'%(i))\n",
    "        i += 1  #更新到下一个新闻\n",
    "        col += 1  #更新col index\n",
    "        TM.sleep(np.random.rand()+0.2)  #暂停一会\n",
    "\n",
    "    except:\n",
    "        key = False\n",
    "             \n",
    "print('用时%s'%(TM.time()-time_begin))\n",
    "driver.close()\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hupu_news(pages = 5):\n",
    "    \n",
    "    import time as TM\n",
    "    \n",
    "    time_begin = TM.time()  #初始化时间\n",
    "    \n",
    "    col = 0  #查找的第i个内容\n",
    "   \n",
    "    page = 1    #初始化页数\n",
    "    \n",
    "    column_name = ['title', 'source', 'content']\n",
    "    \n",
    "    data = pd.DataFrame(columns=column_name)\n",
    "    \n",
    "    print('-----'*8, '\\n准备爬取第1页的内容！！')\n",
    "    \n",
    "    while page <= pages :        #爬取的页数\n",
    "        key = True  #判断是否爬完了一页的内容\n",
    "        i = 1   #初始化当前页的新闻个数\n",
    "        while key:\n",
    "            try:\n",
    "                li = driver.find_element_by_xpath('/html/body/div[3]/div[1]/div[2]/ul/li[%s]'%(i))  #打开第i个新闻内容\n",
    "                txt = re.split(r'\\n', li.text)  #获得文本\n",
    "                title, source = txt[0], txt[1]  #获取信息\n",
    "                ##链接\n",
    "                ##link = driver.find_element_by_xpath('/html/body/div[3]/div[1]/div[2]/ul/li[%s]/div[1]/h4/a'%(i)).get_attribute('href')获得链接\n",
    "                ##链接内容\n",
    "                \n",
    "                driver.find_element_by_xpath('/html/body/div[3]/div[1]/div[2]/ul/li[%s]/div[1]/h4/a'%(i)).click()\n",
    "                driver.switch_to.window(driver.window_handles[-1:][0]) #切换到当前标签\n",
    "                \n",
    "                content = ''\n",
    "                try:\n",
    "                    content = driver.find_element_by_xpath('/html/body/div[4]/div[1]/div[2]/div').text  #获得链接内容\n",
    "                except:\n",
    "                    print('无内容！')\n",
    "                    pass\n",
    "                \n",
    "                driver.close()  #关闭当前标签\n",
    "                \n",
    "                #整理数据到data\n",
    "                data.loc[col, :] = [title, source, content]\n",
    "\n",
    "                ##返回上一级标签\n",
    "                driver.switch_to.window(driver.window_handles[-1:][0])\n",
    "                i += 1  #更新到下一个新闻\n",
    "                col += 1  #更新col index\n",
    "                #TM.sleep(np.random.rand()+0.2)  #暂停一会\n",
    "\n",
    "                \n",
    "            ##如果到这一步，表明第一页内容已经爬完，接下来爬取下一页\n",
    "            except:\n",
    "                print('\\n用时%s秒爬取了%s页的内容共%s条！！'%(TM.time() - time_begin, page, col))\n",
    "                driver.find_element_by_link_text('下一页').click()  #切换到下一页\n",
    "                \n",
    "                key = False  #爬完了当前页，跳出第二个while\n",
    "                page += 1\n",
    "                if page <= pages:\n",
    "                    print('-----'*8, '\\n现在正在爬取第%s页的内容！！\\n'%(page), '-----'*8)\n",
    "                else:\n",
    "                    print('已经爬完了%s页的内容！！共用时%s秒\\n'%(page-1, TM.time() - time_begin), '***'*8)\n",
    "    driver.quit()\n",
    "    return data\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df= pd.read_csv('虎扑NBA新闻5_10.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('123.csv', encoding='GBK', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
